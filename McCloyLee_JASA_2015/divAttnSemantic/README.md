# Divided Attention: Semantic vs Phonetic

This experiment plays four temporally interleaved, spatially distributed word streams and asks listeners for semantic class judgments about the words in specific target streams (targets are any word that mismatches the semantic category of the stream). Target streams are indicated on screen and change from trial to trial; category-to-spatial-location correspondences are fixed across blocks. In a control condition, each the four streams is a single repeated word, and targets are any deviant from that word. Data collection was completed in 2013 November, and results were presented at the 2014 December ASA meeting in San Francisco.

## Files necessary for reproducing the experiment:
- `makeStimuli.py` generates the stimuli used for the experiment.
- `divAttnSemantic.py` is the script for running the experiment.
- `trainingGUI.py` creates a training GUI for the participants, run prior to the main experiment. It is designed to ensure that all listeners know the meanings of the words used in the semantic task, and agree on the categorization of those words.
- `cleanOutput.py` merges the experiment log files (subject responses) with the experiment parameters (MAT files) in preparation for data analysis.
- `analysis.py` does all the data analysis and generates all the figures.

## Helper scripts:
- `calcMeanPitches.py` is a script for determining the mean fundamental frequency of the recorded words, so I would know at what frequency the stimuli should be monotonized. It operates on headerless PitchTier files generated by Praat.
- `getSoundDurations.py` is a script for determining the durations of recorded words (mostly for use in the generation of a trial structure diagram; see `analysis.py`). It outputs `analysis/wordDurations.json`.
- `sampleStim.py` was an early script for stimulus mock-ups when fine-tuning stimulus parameters, and is not a necessary part of reproducing the experiment.
- `lindsey_figure.py` makes a modified version of the trial structure diagram, for describing a related experiment that used six spatial streams instead of four.
- `analysis/importPandas.R` was designed to get pandas-outputted data into R. It is a limited-use script in that it only handles python lists that are flat or have a single level of nesting (e.g., it can't handle >2D arrays). It ended up never really being used, since we didn't end up using mixed models for analysis, and since all the figures were generated with matplotlib.

## Miscellany:
- `documents/McCloy&Lee2013_ASAposter.ai` is the Illustrator source file for the poster.
- The `stimSelection` folder has various scripts related to the selection of words and categories, and some descriptive statistics showing that the categories aren't significantly different from one another in various ways.
